{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Kaggle- What's Cooking\n",
    "Qixiang Zhang  \n",
    "Jul 3rd, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search and validation for each model's best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EXPLORE #########==================\n",
    "# data exploring and basic libraries\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from collections import deque as dq\n",
    "\n",
    "# NLP preprocessing\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize as TK\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "##### MODELING ######===================\n",
    "# from time import time\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# model eval\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# basic multi-class classification models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# binary class classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# One vs All wrapper\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# additional multi-class classification models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - train data\n",
    "rawdf_tr = pd.read_json(path_or_buf='raw_data/train.json').set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess (regular expression + lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute the matched pattern\n",
    "def sub_match(pattern, sub_pattern, ingredients):\n",
    "    for i in ingredients.index.values:\n",
    "        for j in range(len(ingredients[i])):\n",
    "            ingredients[i][j] = re.sub(pattern, sub_pattern, ingredients[i][j].strip())\n",
    "            ingredients[i][j] = ingredients[i][j].strip()\n",
    "    re.purge()\n",
    "    return ingredients\n",
    "\n",
    "def regex_sub_match(series):\n",
    "    # remove all units\n",
    "    p0 = re.compile(r'\\s*(oz|ounc|ounce|pound|lb|inch|inches|kg|to)\\s*[^a-z]')\n",
    "    series = sub_match(p0, ' ', series)\n",
    "    # remove all digits\n",
    "    p1 = re.compile(r'\\d+')\n",
    "    series = sub_match(p1, ' ', series)\n",
    "    # remove all the non-letter characters\n",
    "    p2 = re.compile('[^\\w]')\n",
    "    series = sub_match(p2, ' ', series)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the series from the dataframe\n",
    "ingredients_tr = rawdf_tr['ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex both train and test data\n",
    "ingredients_tr = regex_sub_match(ingredients_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare instance from WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# remove all the words that are not nouns -- keep the essential ingredients\n",
    "def lemma(series):\n",
    "    for i in series.index.values:\n",
    "        for j in range(len(series[i])):\n",
    "            # get rid of all extra spaces\n",
    "            series[i][j] = series[i][j].strip()\n",
    "            # Tokenize a string to split off punctuation other than periods\n",
    "            token = TK(series[i][j])\n",
    "            # set all the plural nouns into singular nouns\n",
    "            for k in range(len(token)):\n",
    "                token[k] = lemmatizer.lemmatize(token[k])\n",
    "            token = ' '.join(token)\n",
    "            # write them back\n",
    "            series[i][j] = token\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize both train and test data\n",
    "ingredients_tr = lemma(ingredients_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy back to the dataframe\n",
    "rawdf_tr['ingredients_lemma'] = ingredients_tr\n",
    "rawdf_tr['ingredients_lemma_string'] = [' '.join(_).strip() for _ in rawdf_tr['ingredients_lemma']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training dataset (train.json) into 85% training/validation and 15% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically train_test_split customized to input cuisine name, outputs are 2 lists of indicies for train and test for the cuisine\n",
    "def tt_split(cuisine):\n",
    "    cuisine_population = rawdf_tr.loc[(rawdf_tr['cuisine'] == cuisine)].index.values\n",
    "    train, test = train_test_split(cuisine_population, test_size=0.15, random_state=0)\n",
    "    train = train.tolist()\n",
    "    test = test.tolist()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_list = rawdf_tr['cuisine'].unique().tolist()\n",
    "# split the training data into 85-15\n",
    "ix_train = [] # 85% for training (and validation)\n",
    "ix_valid = [] # 15% for hold-out test\n",
    "for _ in cuisine_list:\n",
    "    temp_train, temp_valid = tt_split(_)\n",
    "    ix_train += temp_train\n",
    "    ix_valid += temp_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data are split correctly\n",
    "print('top 3 weights', Counter(rawdf_tr['cuisine'].loc[ix_train]).most_common(3))\n",
    "\n",
    "# DataFrame for training\n",
    "traindf = rawdf_tr[['cuisine', 'ingredients_lemma_string']].loc[ix_train].reset_index(drop=True)\n",
    "print('traindf shape: ',traindf.shape)\n",
    "# DataFrame for validation\n",
    "validdf = rawdf_tr[['cuisine', 'ingredients_lemma_string']].loc[ix_valid].reset_index(drop=True)\n",
    "print('validdf shape: ',validdf.shape)\n",
    "print('')\n",
    "\n",
    "# weights check\n",
    "total_recipes_tr = len(rawdf_tr)\n",
    "cuisine_weights = {}\n",
    "for i in cuisine_list:\n",
    "    cuisine_weights[i] = float(dq(rawdf_tr['cuisine']).count(i) / total_recipes_tr)\n",
    "# check train weights\n",
    "print('TRAINING')\n",
    "print('Weight\\t Recipe\\t Cuisine\\n')\n",
    "for _ in (Counter(traindf['cuisine']).most_common()):print(round(_[1]/traindf.cuisine.count()*100, 2),'%\\t',_[1],'\\t', _[0])\n",
    "# check validation weights\n",
    "\n",
    "print('\\nVALIDATION')\n",
    "print('Weight\\t Recipe\\t Cuisine\\n')\n",
    "for _ in (Counter(validdf['cuisine']).most_common()):print(round(_[1]/validdf.cuisine.count()*100, 2),'%\\t',_[1],'\\t', _[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### X_train & X_pred TF-IDF vectorizer\n",
    "\n",
    "# 85% for training and validation ===================\n",
    "# X_train\n",
    "X_train_ls = traindf['ingredients_lemma_string']\n",
    "vectorizertr = TfidfVectorizer(stop_words='english', analyzer=\"word\", max_df=0.65, min_df=2, binary=True)\n",
    "X_train = vectorizertr.fit_transform(X_train_ls)\n",
    "\n",
    "# y_train\n",
    "y_train = traindf['cuisine']\n",
    "# for xgboost the labels need to be labeled with encoder\n",
    "le = LabelEncoder()\n",
    "y_train_ec = le.fit_transform(y_train)\n",
    "\n",
    "# 15% data for the hold-out validation ===============\n",
    "# X_pred\n",
    "X_valid_ls = validdf['ingredients_lemma_string']\n",
    "vectorizerts = TfidfVectorizer(stop_words='english')\n",
    "X_valid = vectorizertr.transform(X_valid_ls)\n",
    "\n",
    "# y_valid as true y for validation\n",
    "y_valid = validdf['cuisine']\n",
    "y_valid_ec = le.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GridSearch Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GridSearchCV with StratifiedKFold to find the best parameters for each model\n",
    "\n",
    "def grid_cv_clf(clf, parameter_dict, X_train, y_train):\n",
    "    # model input such as SVC()\n",
    "    classifier = clf\n",
    "    # stratifiedKFold to maintain class ratio\n",
    "    cv_sets = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    # parameters {'kernel': ['rbf', 'linear'], 'C': [0.001, 0.1, 0.5, 1.0]} for SVC()\n",
    "    params = parameter_dict\n",
    "    # scoring method using accuracy\n",
    "    scoring = 'average_precision'\n",
    "    # grid search and cross validate\n",
    "    grid = GridSearchCV(estimator = classifier,\n",
    "                        param_grid = params,\n",
    "                        scoring = scoring,\n",
    "                        n_jobs = 2,\n",
    "                        cv = cv_sets,\n",
    "                        verbose = 2).fit(X_train, y_train)\n",
    "    # return the best estimator\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (sklearn.ensemble.[RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "param_rf = {'n_estimators':[500, 750, 1000],\n",
    "            'n_jobs':[2],\n",
    "            'oob_score':[True],\n",
    "            'criterion':['gini', 'entropy'],\n",
    "            'max_features': [3, 5, 7],\n",
    "            'random_state':[0],\n",
    "            'verbose': [1]}\n",
    "clf_rf = grid_cv_clf(RandomForestClassifier(), param_rf, X_train, y_train).fit(X_train, y_train)\n",
    "\n",
    "# use accuracy as the metric\n",
    "score_ac_rf = clf_rf.score(X_valid, y_valid)\n",
    "\n",
    "print(clf_rf, '\\naccuracy: %.2f' % (score_ac_rf*100))\n",
    "# accuracy: 75.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (sklearn.naive_bayes.[MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html))\n",
    "\n",
    "According to this [article](https://medium.com/syncedreview/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation-4f5271768ebf), the multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mnb = {'alpha': [0.01, 0.02, 0.035, 0.04, 0.1, 0.5, 1]}\n",
    "\n",
    "clf_mnb = grid_cv_clf(MultinomialNB(), param_mnb, X_train, y_train).fit(X_train, y_train)\n",
    "\n",
    "y_pred_mnb = clf_mnb.predict(X_pred)\n",
    "\n",
    "# use accuracy as the metric\n",
    "score_ac_mnb = clf_mnb.score(X_pred, y_true)\n",
    "\n",
    "print(clf_mnb, '\\naccuracy: %.2f' % (score_ac_mnb*100))\n",
    "# accuracy: 74.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (sklearn.linear_model.[LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lr = {'multi_class': ['multinomial'],\n",
    "            'C':[0.1, 1, 5, 10, 100],\n",
    "            'solver': ['lbfgs','newton-cg', 'sag', 'saga'],\n",
    "            'random_state': [0]}\n",
    "\n",
    "clf_lr = grid_cv_clf(LogisticRegression(), param_lr, X_train, y_train).fit(X_train,y_train)\n",
    "\n",
    "y_pred_lr = clf_lr.predict(X_pred)\n",
    "\n",
    "# use accuracy as the metric\n",
    "score_ac_lr = clf_lr.score(X_pred, y_true)\n",
    "\n",
    "print(clf_lr, '\\naccuracy: %.2f' % (score_ac_lr*100))\n",
    "# accuracy: 78.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network by sklearn (sklearn.neural_network.[MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mlp = {'activation':['logistic', 'relu'],\n",
    "             'solver': ['lbfgs', 'sgd'],\n",
    "             'learning_rate':['constant', 'adaptive', 'invscaling'],\n",
    "             'random_state': [0],\n",
    "             'early_stopping': [True],\n",
    "             'verbose': [True]}\n",
    "\n",
    "clf_mlp = grid_cv_clf(MLPClassifier(), param_mlp, X_train, y_train).fit(X_train, y_train)\n",
    "\n",
    "y_pred_mlp = clf_mlp.predict(X_pred)\n",
    "\n",
    "# use accuracy as the metric\n",
    "score_ac_mlp = clf_mlp.score(X_pred, y_true)\n",
    "\n",
    "print(clf_mlp, '\\naccuracy: %.2f' % (score_ac_mlp*100))\n",
    "# accuracy: 78.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.multiclass.[OneVsRestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier)\n",
    "\n",
    "### Logistic Regression (sklearn.linear_model.[LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ovcr_lr = {'C':[0.001, 0.1, 1, 5, 10],\n",
    "                 'multi_class': ['ovr'],\n",
    "                 'solver': ['lbfgs', 'sag', 'saga'],\n",
    "                 'random_state': [0]}\n",
    "\n",
    "clf_ovrc_lr = OVRC(grid_cv_clf(LogisticRegression(), param_ovcr_lr,X_train,y_train)).fit(X_train, y_train)\n",
    "\n",
    "y_pred_ovrc_lr = clf_ovrc_lr.predict(X_pred)\n",
    "\n",
    "# use accuracy as the metric\n",
    "score_ac_ovrc_lr = clf_ovrc_lr.score(X_pred, y_true)\n",
    "\n",
    "print(clf_ovrc_lr, '\\naccuracy: %.2f' % (score_ac_ovrc_lr*100))\n",
    "# accuracy: 79.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classification (sklearn.svm.[SVC¶](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ovrc_svm = {'C': [0.01, 0.1, 1, 3.25, 10, 100],\n",
    "                  'gamma': [1, 50],\n",
    "                  'coef0': [0, 1, 2],\n",
    "                  'cache_size': [200, 500],\n",
    "                  'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "                  'random_state': [0]}\n",
    "\n",
    "clf_ovrc_svm = OVRC(grid_cv_clf(SVC(), param_ovrc_svm, X_train, y_train)).fit(X_train, y_train)\n",
    "\n",
    "y_pred_ovrc_svm = clf_ovrc_svm.predict(X_pred)\n",
    "\n",
    "# use accuracy as the metric\n",
    "score_ac_ovrc_svm = clf_ovrc_svm.score(X_pred, y_true)\n",
    "\n",
    "print(clf_ovrc_svm, '\\naccuracy: %.2f' % (score_ac_ovrc_svm*100))\n",
    "# accuracy: 80.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD (sklearn.linear_model.[SGDClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ovcr_sgd = {'loss':['perceptron', 'modified_huber'],\n",
    "                  'learning_rate':['constant', 'optimal', 'invscaling'],\n",
    "                  'penalty': ['l2'],\n",
    "                  'verbose':[2],\n",
    "                  'n_jobs': [2],\n",
    "                  'random_state': [0]}\n",
    "\n",
    "clf_ovrc_sgd = OVRC(grid_cv_clf(SGDClassifier(), param_ovcr_sgd ,X_train,y_train)).fit(X_train, y_train)\n",
    "\n",
    "y_pred_ovrc_sgd = clf_ovrc_sgd.predict(X_pred)\n",
    "\n",
    "# use accuracy as the metric\n",
    "score_ac_ovrc_sgd = clf_ovrc_sgd.score(X_pred, y_true)\n",
    "\n",
    "print(clf_ovrc_sgd, '\\naccuracy: %.2f' % (score_ac_ovrc_sgd*100))\n",
    "# accuracy: 77.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_xgb = {'n_jobs':[2],\n",
    "             'learning_rate': [0.001, 0.01],\n",
    "             'gamma':[0.1, 1],\n",
    "             'subsample':[0.8],\n",
    "             'max_depth': [6, 8, 12],\n",
    "             'random_state':[0],\n",
    "             'n_estimators': [750, 1000]}\n",
    "\n",
    "clf_xgb = grid_cv_clf(XGBClassifier(), param_xgb, X_train, y_train_ec).fit(X_train, y_train_ec)\n",
    "\n",
    "y_pred_xgb = clf_xgb.predict(X_pred)\n",
    "y_pred_xgb = le.inverse_transform(y_pred_xgb)\n",
    "score_ac_xgb = accuracy_score(y_pred_xgb, y_true)\n",
    "\n",
    "print(clf_xgb, '\\naccuracy: %.2f' % (score_ac_xgb*100))\n",
    "# accuracy: 77.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LightGBM](https://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/sklearn.html#LGBMClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gbm = {'n_jobs':[2],\n",
    "             'objective': ['multiclass'],\n",
    "             'boosting_type':['gbdt'],\n",
    "             'learning_rate': [0.01, 0.05],\n",
    "             'gamma':[1],\n",
    "             'subsample':[0.8],\n",
    "             'max_depth': [6],\n",
    "             'random_state':[0],\n",
    "             'n_estimators': [500, 1000]}\n",
    "\n",
    "clf_gbm = grid_cv_clf(LGBMClassifier(), param_gbm, X_train, y_train_ec).fit(X_train, y_train_ec)\n",
    "\n",
    "y_pred_gbm = clf_gbm.predict(X_pred)\n",
    "y_pred_gbm = le.inverse_transform(y_pred_gbm)\n",
    "score_ac_gbm = accuracy_score(y_pred_gbm, y_true)\n",
    "\n",
    "print(clf_gbm, '\\naccuracy: %.2f' % (score_ac_gbm*100))\n",
    "# 10% - accuracy: 75.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "kitchen",
   "language": "python",
   "name": "kitchen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
